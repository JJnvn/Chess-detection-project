{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":83828,"databundleVersionId":10451389,"sourceType":"competition"},{"sourceId":10155692,"sourceType":"datasetVersion","datasetId":6270190},{"sourceId":10162773,"sourceType":"datasetVersion","datasetId":6275657},{"sourceId":10162967,"sourceType":"datasetVersion","datasetId":6275801},{"sourceId":10165065,"sourceType":"datasetVersion","datasetId":6277215},{"sourceId":10165504,"sourceType":"datasetVersion","datasetId":6277507},{"sourceId":191720,"sourceType":"modelInstanceVersion","modelInstanceId":163422,"modelId":185784},{"sourceId":192240,"sourceType":"modelInstanceVersion","modelInstanceId":163901,"modelId":186251}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mediapipe\n!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:08:51.095854Z","iopub.execute_input":"2024-12-11T04:08:51.096281Z","iopub.status.idle":"2024-12-11T04:09:11.400881Z","shell.execute_reply.started":"2024-12-11T04:08:51.096241Z","shell.execute_reply":"2024-12-11T04:09:11.399275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.403492Z","iopub.execute_input":"2024-12-11T04:09:11.403908Z","iopub.status.idle":"2024-12-11T04:09:11.40984Z","shell.execute_reply.started":"2024-12-11T04:09:11.403869Z","shell.execute_reply":"2024-12-11T04:09:11.408707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\nimport numpy as np\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.411034Z","iopub.execute_input":"2024-12-11T04:09:11.411405Z","iopub.status.idle":"2024-12-11T04:09:11.431288Z","shell.execute_reply.started":"2024-12-11T04:09:11.411372Z","shell.execute_reply":"2024-12-11T04:09:11.430116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(os.getcwd())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.432622Z","iopub.execute_input":"2024-12-11T04:09:11.432994Z","iopub.status.idle":"2024-12-11T04:09:11.445327Z","shell.execute_reply.started":"2024-12-11T04:09:11.432959Z","shell.execute_reply":"2024-12-11T04:09:11.444103Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def piece2Num(piece):\n    cases = {\n        \"black-bishop\": lambda: 201,\n        \"black-king\": lambda: 202,\n        \"black-knight\": lambda: 203,\n        \"black-pawn\": lambda: 204,\n        \"black-queen\": lambda: 205,\n        \"black-rook\": lambda: 206,\n        \"white-bishop\": lambda: 301,\n        \"white-king\": lambda: 302,\n        \"white-knight\": lambda: 303,\n        \"white-pawn\": lambda: 304,\n        \"white-queen\": lambda: 305,\n        \"white-rook\": lambda: 306,\n    }\n    return cases.get(piece, lambda: \"error from function piece2Num -> unknow piece\")()\ndef num2PieceString(piece):\n    cases = {\n        201: lambda: \"black-bishop\",\n        202: lambda: \"black-king\",\n        203: lambda: \"black-knight\",\n        204: lambda: \"black-pawn\",\n        205: lambda: \"black-queen\",\n        206: lambda: \"black-rook\",\n        301: lambda: \"white-bishop\",\n        302: lambda: \"white-king\",\n        303: lambda: \"white-knight\",\n        304: lambda: \"white-pawn\",\n        305: lambda: \"white-queen\",\n        306: lambda: \"white-rook\",\n    }\n    return cases.get(piece, lambda: \"error from function piece2Num -> unknow piece\")()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.448696Z","iopub.execute_input":"2024-12-11T04:09:11.449362Z","iopub.status.idle":"2024-12-11T04:09:11.46229Z","shell.execute_reply.started":"2024-12-11T04:09:11.449318Z","shell.execute_reply":"2024-12-11T04:09:11.461241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert2Xaxis(letter):\n    cases = {\n        \"a\": lambda: 7,\n        \"b\": lambda: 6,\n        \"c\": lambda: 5,\n        \"d\": lambda: 4,\n        \"e\": lambda: 3,\n        \"f\": lambda: 2,\n        \"g\": lambda: 1,\n        \"h\": lambda: 0,\n    }\n    return cases.get(letter, lambda: \"error from function convert2Xaxis\")()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.463611Z","iopub.execute_input":"2024-12-11T04:09:11.463964Z","iopub.status.idle":"2024-12-11T04:09:11.478794Z","shell.execute_reply.started":"2024-12-11T04:09:11.463925Z","shell.execute_reply":"2024-12-11T04:09:11.477522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def handleSingleInput(data):\n    tmp = np.full((8, 8), 7)\n    for i in range(len(data)):\n        if (data[i][1] == None):\n            continue\n        else:\n            tmp[int(data[i][1][1])-1][convert2Xaxis(data[i][1][0])] = piece2Num(data[i][0])\n    return tmp\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.480899Z","iopub.execute_input":"2024-12-11T04:09:11.4814Z","iopub.status.idle":"2024-12-11T04:09:11.494539Z","shell.execute_reply.started":"2024-12-11T04:09:11.481352Z","shell.execute_reply":"2024-12-11T04:09:11.493352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def handleMultipleInput(dataArray):\n    result = []\n    for i in range(len(dataArray)):\n        result.append(handleSingleInput(dataArray[i]))\n    return result\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.496122Z","iopub.execute_input":"2024-12-11T04:09:11.497267Z","iopub.status.idle":"2024-12-11T04:09:11.507657Z","shell.execute_reply.started":"2024-12-11T04:09:11.497211Z","shell.execute_reply":"2024-12-11T04:09:11.506553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def handleduplicateLabel(dataArray):\n    result = []\n    for i in range(len(dataArray)):\n        data = dataArray[i]\n        tmp = dict()\n        detected_chesses = []\n        for j in range(len(data)):\n            chess_name = data[j][0]\n            label = data[j][1]\n            confidence_score = data[j][2]\n            if (label not in tmp):\n                tmp[label] = (confidence_score, chess_name)\n                detected_chesses.append((chess_name, label))\n            else:\n                if (tmp[label][0] < confidence_score):\n                    detected_chesses.remove((tmp[label][1], label))\n                    detected_chesses.append((chess_name, label))\n                    \n        result.append(detected_chesses)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.509032Z","iopub.execute_input":"2024-12-11T04:09:11.509466Z","iopub.status.idle":"2024-12-11T04:09:11.520092Z","shell.execute_reply.started":"2024-12-11T04:09:11.509419Z","shell.execute_reply":"2024-12-11T04:09:11.518881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def getAmountChessPiece(dataArray):\n    result = []\n    for i in range(len(dataArray)):\n        c = 0\n        for j in range(8):\n            for k in range(8):\n                if (dataArray[i][j][k] != 7):\n                    c += 1\n        result.append(c)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.521647Z","iopub.execute_input":"2024-12-11T04:09:11.522063Z","iopub.status.idle":"2024-12-11T04:09:11.5361Z","shell.execute_reply.started":"2024-12-11T04:09:11.522003Z","shell.execute_reply":"2024-12-11T04:09:11.534733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert2LetterBoard(i):\n    cases = {\n        7: lambda: \"a\",\n        6: lambda: \"b\",\n        5: lambda: \"c\",\n        4: lambda: \"d\",\n        3: lambda: \"e\",\n        2: lambda: \"f\",\n        1: lambda: \"g\",\n        0: lambda: \"h\",\n    }\n    return cases.get(i, lambda: \"error from function convert2LetterBoard\")()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.537727Z","iopub.execute_input":"2024-12-11T04:09:11.538089Z","iopub.status.idle":"2024-12-11T04:09:11.548454Z","shell.execute_reply.started":"2024-12-11T04:09:11.538055Z","shell.execute_reply":"2024-12-11T04:09:11.547264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def num2piece(num):\n    cases = {\n        201: lambda: \"B\",\n        202: lambda: \"K\",\n        203: lambda: \"N\",\n        204: lambda: \"\",\n        205: lambda: \"Q\",\n        206: lambda: \"R\",\n        301: lambda: \"B\",\n        302: lambda: \"K\",\n        303: lambda: \"N\",\n        304: lambda: \"\",\n        305: lambda: \"Q\",\n        306: lambda: \"R\",\n        7: lambda: \"wtf why empty here!\",\n    }\n    return cases.get(num, lambda: \"error from function num2piece -> unknow number\")()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.54987Z","iopub.execute_input":"2024-12-11T04:09:11.550259Z","iopub.status.idle":"2024-12-11T04:09:11.560975Z","shell.execute_reply.started":"2024-12-11T04:09:11.55022Z","shell.execute_reply":"2024-12-11T04:09:11.559986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def checkDiffArray(array1, array2):\n    out1 = list(set(array1)-set(array2))\n    out2 = list(set(array2)-set(array1))\n    if (len(out1) == 0):\n        return ('-', '-')\n    if (len(out2) == 0):\n        return ('-', '-')\n    return (out1[0], out2[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.562414Z","iopub.execute_input":"2024-12-11T04:09:11.562851Z","iopub.status.idle":"2024-12-11T04:09:11.57712Z","shell.execute_reply.started":"2024-12-11T04:09:11.562794Z","shell.execute_reply":"2024-12-11T04:09:11.576143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def findPrevAndPresent(m, n, piece, cleanData):\n    prev = []\n    next = []\n    for i in range(len(cleanData[m])):\n        if (cleanData[m][i][0] == num2PieceString(piece)):\n            prev.append(cleanData[m][i][1])\n    for i in range(len(cleanData[n])):\n        if (cleanData[n][i][0] == num2PieceString(piece)):\n            next.append(cleanData[n][i][1])\n    # print(prev)\n    # print(next)\n    return checkDiffArray(prev, next)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.580956Z","iopub.execute_input":"2024-12-11T04:09:11.581351Z","iopub.status.idle":"2024-12-11T04:09:11.59289Z","shell.execute_reply.started":"2024-12-11T04:09:11.58131Z","shell.execute_reply":"2024-12-11T04:09:11.591767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validMove(moved_from, moved_to, piece, move_type):\n    if (len(moved_from) < 2 or len(moved_to) < 2): return False\n    x1 = convert2Xaxis(moved_from[0])\n    y1 = int(moved_from[1])\n    x2 = convert2Xaxis(moved_to[0])\n    y2 = int(moved_to[1])\n    king_move = [(1,0), (-1,0), (0,1), (0,-1), (1,1), (-1,-1), (1,-1), (-1,1)]\n    horse_move = [(-2,1), (-2,-1), (2,1), (2,-1), (1,2), (1,-2), (-1, 2), (-1,-2)]\n\n    if (piece % 100 == 4) : # check pawn\n        if (piece // 100 == 2) : #black\n            if (move_type) : #walk\n                if (moved_to == moved_from[0] + str(int (moved_from[1]) - 1) or moved_to == moved_from[0] + str(int (moved_from[1]) - 2)) :\n                    return True\n                else :  return False\n            else :\n                return True\n\n        elif (piece // 100 == 3) : #white\n            if (move_type) : #walk\n                # print(moved_from[1])\n                # print(str(int(moved_from[1]) - 1))\n                if (moved_to == moved_from[0] + str(int(moved_from[1]) + 1) or moved_to == moved_from[0] + str(int (moved_from[1]) + 2)) :\n                    return True\n                else : return False\n    \n    elif (piece % 100 == 1) : # check bishop\n        if (abs(x1 - x2) == abs(y1 - y2)) :\n            return True\n        else : return False\n    \n    elif (piece % 100 == 6) : # check rook\n        if (x1 == x2 or y1 == y2) :\n            return True\n        else : return False\n\n    elif (piece % 100 == 5) : # check queen\n        if (x1 == x2 or y1 == y2 or (abs(x1 - x2) == abs(y1 - y2))) :\n            return True\n        else : return False\n    \n    elif (piece % 100 == 2) :#check king\n        for pos in king_move :\n            if (x1 + pos[0] == x2 and y1 + pos[1] == y2) : return True\n        return False\n    \n    elif (piece % 100 == 3) : # check horse\n        for pos in horse_move :\n            if (x1 + pos[0] == x2 and y1 + pos[1] == y2) : return True\n        return False\n\n    return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.594309Z","iopub.execute_input":"2024-12-11T04:09:11.594641Z","iopub.status.idle":"2024-12-11T04:09:11.61108Z","shell.execute_reply.started":"2024-12-11T04:09:11.59461Z","shell.execute_reply":"2024-12-11T04:09:11.609695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def lastResult(testSet):\n    result = []\n    c = 0\n    for m in range(len(testSet)-1):\n        n = m + 1\n        testcaseM = testSet[m]\n        testcaseN = testSet[n]\n        for i in range(8):\n            for j in range(8):\n                if (testcaseM[i][j] == testcaseN[i][j]):\n                    continue \n                # เดินปกติ\n                if (testcaseM[i][j] == 7 and testcaseN[i][j] != 7):\n                    # check pawn and Bishop\n                    ##################################\n                    if (testcaseN[i][j] % 10 == 4 or testcaseN[i][j] % 10 == 1):\n                    #####################################\n                        move = findPrevAndPresent(m, n, testcaseN[i][j], cleanData)\n                        # print(move[0], move[1], testcaseN[i][j], convert2LetterBoard(j) ,str(i+1), testcaseM[i][j], testcaseN[i][j], m ,n)\n                        if (validMove(move[0], move[1], testcaseN[i][j], 1)):\n                            if (c == 0 and (testcaseN[i][j]//100) % 2 == 0):\n                                result.append('..')\n                            result.append(num2piece(testcaseN[i][j]) + convert2LetterBoard(j) + str(i+1))\n                    #########################################\n                    else:\n                        if (c == 0 and (testcaseN[i][j]//100) % 2 == 0):\n                            result.append('..')\n                        result.append(num2piece(testcaseN[i][j]) + convert2LetterBoard(j) + str(i+1))\n                    c += 1\n                    ########################################################\n                    # print(\"move first condition:\", testcaseN[i][j], \"at position:\", convert2LetterBoard(j), i+1)\n                # โดนกิน\n                if (lenData[m] == lenData[n]): continue\n\n                if (testcaseM[i][j] != 7 and testcaseN[i][j] != 7 and testcaseM[i][j] != testcaseN[i][j]):\n                    # check pawn and Bishop\n                    ###############################\n                    if (testcaseN[i][j] % 10 == 4 or testcaseN[i][j] % 10 == 1):\n                    #################################\n                        move = findPrevAndPresent(m, n, testcaseN[i][j], cleanData)\n                        # print(move[0], move[1], testcaseN[i][j])\n                        if (validMove(move[0], move[1], testcaseN[i][j], 0)):\n                            if (c == 0 and (testcaseN[i][j]//100) % 2 == 0):\n                                result.append('..')\n                            if (testcaseN[i][j] % 10 == 4):\n                                if (i-1>=0 and j-1>=0 and testcaseM[i-1][j-1] % 10 == 4 and testcaseN[i-1][j-1] == 7):\n                                    result.append(convert2LetterBoard(j-1) + num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                                elif (i-1>=0 and j+1<=7 and testcaseM[i-1][j+1] % 10 == 4 and testcaseN[i-1][j+1] == 7):\n                                    result.append(convert2LetterBoard(j+1) + num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                                elif (i+1<=7 and j-1>=0 and testcaseM[i+1][j-1] % 10 == 4 and testcaseN[i+1][j-1] == 7):\n                                    result.append(convert2LetterBoard(j-1) + num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                                elif (i+1<=7 and j+1<=7 and testcaseM[i+1][j+1] % 10 == 4 and testcaseN[i+1][j+1] == 7):\n                                    result.append(convert2LetterBoard(j+1) + num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                            else :\n                                result.append(num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                    #####################\n                    else:\n                        move = findPrevAndPresent(m, n, testcaseN[i][j], cleanData)\n                        # print(move[0], move[1], testcaseN[i][j], convert2LetterBoard(j) ,str(i+1), testcaseM[i][j], testcaseN[i][j], m ,n)\n                        if (c == 0 and (testcaseN[i][j]//100) % 2 == 0):\n                            result.append('..')\n                        if (testcaseN[i][j] % 10 == 4):\n                            if (i-1>=0 and j-1>=0 and testcaseM[i-1][j-1] % 10 == 4 and testcaseN[i-1][j-1] == 7):\n                                result.append(convert2LetterBoard(j-1) + num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                            elif (i-1>=0 and j+1<=7 and testcaseM[i-1][j+1] % 10 == 4 and testcaseN[i-1][j+1] == 7):\n                                result.append(convert2LetterBoard(j+1) + num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                            elif (i+1<=7 and j-1>=0 and testcaseM[i+1][j-1] % 10 == 4 and testcaseN[i+1][j-1] == 7):\n                                result.append(convert2LetterBoard(j-1) + num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                            elif (i+1<=7 and j+1<=7 and testcaseM[i+1][j+1] % 10 == 4 and testcaseN[i+1][j+1] == 7):\n                                result.append(convert2LetterBoard(j+1) + num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                        else :\n                            result.append(num2piece(testcaseN[i][j]) + 'x' + convert2LetterBoard(j) + str(i+1))\n                    ########################\n                    c += 1\n                    # print(\"move second condition\", testcaseN[i][j], \"at position:\", convert2LetterBoard(j), 'x', i+1)\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.612781Z","iopub.execute_input":"2024-12-11T04:09:11.613831Z","iopub.status.idle":"2024-12-11T04:09:11.641214Z","shell.execute_reply.started":"2024-12-11T04:09:11.613771Z","shell.execute_reply":"2024-12-11T04:09:11.640099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def formatOutput(list) :\n  i = 2\n  out = '1. '\n  for j in range(len(list)):\n    out += list[j] + ' '\n    if (j % 2 == 1 and j != len(list) - 1):\n      out += str(i) + '. '\n      i += 1\n  return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.642604Z","iopub.execute_input":"2024-12-11T04:09:11.642935Z","iopub.status.idle":"2024-12-11T04:09:11.658811Z","shell.execute_reply.started":"2024-12-11T04:09:11.642904Z","shell.execute_reply":"2024-12-11T04:09:11.657679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def unsharp_mask(image, kernel_size=(5, 5), alpha=1.5, beta=-0.5, gamma=0):\n    # Blur the image\n    blurred = cv2.GaussianBlur(image, kernel_size, 0)\n    \n    # Combine original and blurred images\n    sharpened = cv2.addWeighted(image, alpha, blurred, beta, gamma)\n    return sharpened\n\ndef get_largest_connected_component(edges): #mai dai chai\n    # Find contours from the edges\n    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    if not contours:\n        print(\"No contours found.\")\n        return None, np.zeros_like(edges)\n\n    # Find the largest contour by area\n    largest_contour = max(contours, key=cv2.contourArea)\n\n    # Compute the convex hull of the largest contour\n    convex_hull = cv2.convexHull(largest_contour)\n\n    # Create a blank mask\n    mask = np.zeros_like(edges)\n\n    # Draw the largest contour on the mask\n    cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n    # cv2.drawContours(mask, [convex_hull], -1, 255, thickness=1)\n\n    return largest_contour, mask\n\ndef canny_edge(image, lower_th, upper_th):\n    median = np.median(image)  # Calculate median pixel value\n    # print(\"median\", median)\n    adjust = 0.5\n    lower_threshold = max(0, (1.0 + lower_th ) * median)  # Lower threshold\n    upper_threshold = min(255, (1.0 + upper_th) * median)  # Upper threshold\n\n    # print(\"lower_th\", lower_threshold)\n    # print(\"upper_th\", upper_threshold)\n\n    edges = cv2.Canny(image, lower_threshold, upper_threshold)\n\n    return edges\n\ndef select_connected_edges(edges):\n    # Apply morphological closing to close small gaps between edges\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))  # Adjust kernel size as needed\n    closed_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n\n    # Find contours of the connected components\n    contours, _ = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    # Create a blank mask for the selected edges\n    selected_edges = np.zeros_like(edges)\n\n    # Iterate over the contours and select large connected components\n    big_contours = []\n\n    for contour in contours:\n        if cv2.contourArea(contour) > 10000:  # Adjust area threshold as needed\n            # Draw the contour on the selected edges mask\n            # print(\"area\", cv2.contourArea(contour))\n            big_contours.append(contour)\n\n    # print(\"big contour\", len(big_contours))\n    largest_contour = max(big_contours, key=cv2.contourArea)\n    cv2.drawContours(selected_edges, [largest_contour], -1, 255, thickness=1)\n\n    return selected_edges\n\ndef detect_chessboard_with_hough(image):\n    \"\"\"\n    Detects the edges of a chessboard using the Hough Line Transform.\n    \"\"\"\n    \n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    lower_bound = 0\n    upper_bound = 20\n    new_value = 255\n\n    mask = cv2.inRange(image, lower_bound, upper_bound)\n\n    image[mask > 0] = new_value\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n\n    dummy = image.copy()\n\n    # Apply sharpening\n    sharpened_image = unsharp_mask(blurred)\n\n    #-----------------------------------------------------------------\n\n    # cv2.imshow(\"sharpened\", sharpened_image)\n    # cv2.waitKey(0)\n    # cv2.destroyAllWindows()\n\n    #-----------------------------------------------------------------\n\n    # Use Canny edge detection\n    edges = canny_edge(sharpened_image, -0.4, -0.2)\n\n    #-----------------------------------------------------------------\n\n    # cv2.imshow(\"canny edge\", edges)\n    # cv2.waitKey(0)\n    # cv2.destroyAllWindows()\n\n    #-----------------------------------------------------------------\n\n    # largest_contour, largest_component_mask = get_largest_connected_component(edges)\n\n    selected_closed_edges = select_connected_edges(edges)\n\n    #-----------------------------------------------------------------\n\n    # cv2.imshow(\"selected closed edge\", selected_closed_edges)\n    # cv2.waitKey(0)\n    # cv2.destroyAllWindows()\n\n    #-----------------------------------------------------------------\n\n    # Use Hough Line Transform to detect lines\n    lines = cv2.HoughLinesP(selected_closed_edges, rho=1, theta=np.pi / 180, threshold=100, minLineLength=30, maxLineGap=120)\n\n    # print(\"len(lines)\", len(lines))\n\n    if lines is not None:\n        # Convert lines to a set of endpoints\n        lines = lines[:, 0]  # Remove the unnecessary dimension\n        image_with_lines = image.copy()\n        \n        # Draw detected lines\n        for x1, y1, x2, y2 in lines:\n            cv2.line(image_with_lines, (x1, y1), (x2, y2), (0, 255, 0), 2)\n\n        # Find quadrilateral (chessboard edges) from lines\n        chessboard_edges = find_chessboard_edges(lines, image.shape)\n\n        if chessboard_edges is not None:\n            # Draw the detected chessboard edges\n            for (x1, y1), (x2, y2) in zip(chessboard_edges, chessboard_edges[1:] + [chessboard_edges[0]]):\n                cv2.line(image_with_lines, (x1, y1), (x2, y2), (255, 0, 0), 3)\n\n        return image_with_lines, chessboard_edges\n\n    return image, []\n\ndef are_sides_parallel(points, tolerance=0.5):\n    # Calculate slopes of sides\n    slopes = []\n    for i in range(4):\n        x1, y1 = points[i]\n        x2, y2 = points[(i + 1) % 4]  # Next point\n        if x2 - x1 != 0:  # Avoid division by zero\n            slopes.append((y2 - y1) / (x2 - x1))\n        else:\n            slopes.append(float('inf'))  # Vertical line\n\n    # Check if opposite sides are parallel (slopes are approximately equal)\n    # print(\"slope 1\", abs(slopes[0] - slopes[2]))\n    # print(\"slope 2\", abs(slopes[1] - slopes[3]))\n    return abs(slopes[0] - slopes[2]) < tolerance and abs(slopes[1] - slopes[3]) < tolerance\n\ndef find_chessboard_edges(lines, image_shape): # have problem with convex hull\n    \"\"\"\n    Filters lines to find the chessboard edges by looking for four lines\n    that form a quadrilateral around the chessboard.\n    \"\"\"\n    # Convert lines into a set of points\n    points = []\n    for x1, y1, x2, y2 in lines:\n        points.append((x1, y1))\n        points.append((x2, y2))\n\n    points = np.array(points)\n\n    # Find a convex hull of the points\n    hull = cv2.convexHull(points)\n    if len(hull) < 4:\n        return None  # Not enough points to form a quadrilateral\n\n    # Approximate the convex hull to a quadrilateral\n    epsilon = 0.01 * cv2.arcLength(hull, True)\n    approx = cv2.approxPolyDP(hull, epsilon, True)\n\n    # if len(approx) == 4 :\n    if len(approx) == 4 and are_sides_parallel([(pt[0][0], pt[0][1]) for pt in approx]):\n        return [(pt[0][0], pt[0][1]) for pt in approx]  # Return the points of the quadrilateral\n\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.660523Z","iopub.execute_input":"2024-12-11T04:09:11.661564Z","iopub.status.idle":"2024-12-11T04:09:11.685374Z","shell.execute_reply.started":"2024-12-11T04:09:11.661511Z","shell.execute_reply":"2024-12-11T04:09:11.684253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\ndef detect_chessboard_edges(frame):\n    \"\"\"\n    Detect chessboard edges in the frame using Hough Lines and return the edges and mask.\n    \"\"\"\n    height, width = frame.shape[:2]\n\n    # Define ROI (optional: adjust margins based on expected chessboard location)\n    margin = 50\n    roi = frame[margin:height - margin, margin:width - margin]\n\n    # Convert to grayscale and apply edge detection\n    lower_bound = 0\n    upper_bound = 10\n    new_value = 255\n    mask = cv2.inRange(frame, lower_bound, upper_bound)\n    frame[mask > 0] = new_value\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n\n    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n    sharpened_image = unsharp_mask(blurred)\n    edges = canny_edge(sharpened_image, -0.4, -0.2)\n    edges = select_connected_edges(edges)  # Custom function to select the largest connected edges\n\n    # Morphological operations to close gaps in edges\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n    closed_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n\n\n    scale_width = 800 / closed_edges.shape[1]\n    scale_height = 600 / closed_edges.shape[0]\n    scale = min(scale_width, scale_height)\n    resized_frame = cv2.resize(closed_edges, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n    # cv2.imshow(\"closed_edges\", resized_frame)\n    # cv2.waitKey(0)\n    # cv2.destroyAllWindows\n\n    # Find contours\n    contours, _ = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    # Filter contours by area (remove small or noisy contours)\n    filtered_contours = [c for c in contours if cv2.contourArea(c) > 10000]\n\n    # Create a blank mask and draw the largest contour (assume it's the chessboard)\n    mask = np.zeros_like(edges)\n    largest_contour = None\n    if filtered_contours:\n        largest_contour = max(filtered_contours, key=cv2.contourArea)\n        cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n\n    # Adjust the detected contour to match the full frame (consider the ROI margins)\n    board_edges = np.zeros_like(frame)\n    if filtered_contours:\n        largest_contour = np.array(largest_contour)\n        # largest_contour = np.array(largest_contour) + [margin, margin] # use roi\n        cv2.drawContours(board_edges, [largest_contour], -1, (0, 255, 0), 2)\n\n    # Apply Hough Line Detection to the closed edges\n    lines = cv2.HoughLinesP(closed_edges, rho=1, theta=np.pi / 180, threshold=100, minLineLength=150, maxLineGap=120) # best (1, 180, 100, 150, 120) ,(100, 500, 500)\n\n    chessboard_edges = find_chessboard_edges(lines[0], frame.shape)\n\n    #-------------------------------------------v\n\n    # image_with_lines = frame.copy()\n    # if chessboard_edges is not None:\n    # # Draw the detected chessboard edges\n    #     for (x1, y1), (x2, y2) in zip(chessboard_edges, chessboard_edges[1:] + [chessboard_edges[0]]):\n    #         cv2.line(image_with_lines, (x1, y1), (x2, y2), (255, 0, 0), 3)\n\n    # return image_with_lines, chessboard_edges\n\n    #-------------------------------------------^\n\n    if lines is not None:\n        points = []\n    for line in lines:\n        x1, y1, x2, y2 = line[0]\n        points.append((x1, y1))\n        points.append((x2, y2))\n        # Draw the lines on the board edges (optional visualization)\n        cv2.line(board_edges, (x1, y1), (x2, y2), (0, 0, 255), 2)\n\n    # Convert points to a NumPy array\n    points = np.array(points)\n\n    # Find the convex hull around the points\n    hull = cv2.convexHull(points)\n\n    # Approximate the convex hull to a quadrilateral\n    epsilon = 0.02 * cv2.arcLength(hull, True)  # Adjust epsilon as needed\n    approx = cv2.approxPolyDP(hull, epsilon, True)\n\n    # Ensure the approximation is a rectangle or square (4 points)\n    if len(approx) == 4:\n        # Draw the rectangle or square on the board edges for visualization\n        cv2.polylines(board_edges, [approx], isClosed=True, color=(0, 255, 255), thickness=2)\n\n        # Optionally, you can extract the points as the final rectangle\n        rect_points = [tuple(pt[0]) for pt in approx]\n\n    return rect_points\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.687146Z","iopub.execute_input":"2024-12-11T04:09:11.687504Z","iopub.status.idle":"2024-12-11T04:09:11.7059Z","shell.execute_reply.started":"2024-12-11T04:09:11.687472Z","shell.execute_reply":"2024-12-11T04:09:11.704668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def distance_squared(point):\n    x, y = point\n    return x**2 + y**2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.707175Z","iopub.execute_input":"2024-12-11T04:09:11.707502Z","iopub.status.idle":"2024-12-11T04:09:11.720492Z","shell.execute_reply.started":"2024-12-11T04:09:11.707473Z","shell.execute_reply":"2024-12-11T04:09:11.719439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\n\ndef rotate_video_swap_dimensions(video_path, rotate_keyword='rotate', output_suffix='_rotated'):\n    \"\"\"\n    Rotates the video 90 degrees clockwise and swaps its width and height if the file path contains the specified keyword.\n    \n    Parameters:\n        video_path (str): Path to the original video file.\n        rotate_keyword (str): Keyword to check in the file path to decide rotation.\n        output_suffix (str): Suffix to append to the original filename for the rotated video.\n        \n    Returns:\n        str: Path to the rotated video if rotation was performed, else the original video path.\n    \"\"\"\n    \n    # Check if the specified keyword is in the file path (case-insensitive)\n    if rotate_keyword in video_path:\n        # Generate the rotated video path by appending the suffix before the file extension\n        base, ext = os.path.splitext(video_path)\n        rotated_video_path = \"/kaggle/working/2_Move_rotate_student_rotated.mp4\"\n        \n        # Open the original video\n        cap = cv2.VideoCapture(video_path)\n        if not cap.isOpened():\n            raise IOError(f\"Cannot open video file: {video_path}\")\n        \n        # Retrieve original video properties\n        fps = cap.get(cv2.CAP_PROP_FPS)\n        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        \n        # Define the codec and create VideoWriter object with swapped dimensions\n        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # You can change the codec if needed\n        out = cv2.VideoWriter(rotated_video_path, fourcc, fps, (original_height, original_width))\n        \n        if not out.isOpened():\n            cap.release()\n            raise IOError(f\"Cannot write to video file: {rotated_video_path}\")\n        \n        print(f\"Starting rotation of video: {video_path}\")\n        print(f\"Original resolution: {original_width}x{original_height}\")\n        print(f\"Rotated resolution: {original_height}x{original_width}\")\n        print(f\"Total frames to process: {frame_count}\")\n        \n        frame_idx = 0\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break  # End of video\n            \n            # Rotate the frame 90 degrees clockwise\n            # OpenCV's rotate function changes the resolution accordingly\n            rotated_frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n            \n            # Write the rotated frame to the output video\n            out.write(rotated_frame)\n            \n            frame_idx += 1\n            if frame_idx % 100 == 0 or frame_idx == frame_count:\n                print(f\"Processed {frame_idx}/{frame_count} frames...\")\n        \n        # Release resources\n        cap.release()\n        out.release()\n        \n        print(f\"Rotation complete. Rotated video saved at: {rotated_video_path}\")\n        \n        return rotated_video_path\n    else:\n        print(f\"No rotation needed for video: {video_path}\")\n        return video_path\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.72196Z","iopub.execute_input":"2024-12-11T04:09:11.722328Z","iopub.status.idle":"2024-12-11T04:09:11.7377Z","shell.execute_reply.started":"2024-12-11T04:09:11.722294Z","shell.execute_reply":"2024-12-11T04:09:11.736558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport mediapipe as mp\n\ndef detectHand(frame, hand_detector):\n    # Convert the BGR image to RGB.\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    \n    # Process the frame and detect hands.\n    results = hand_detector.process(rgb_frame)\n    \n    # Check if any hands are detected.\n    if results.multi_hand_landmarks:\n        return True\n    return False\n\ndef locateChess(vids, chessboardLabel):\n    \"\"\"\n    Processes a video to locate chessboards, optionally rotating frames if 'rotate' is in the filename.\n\n    Parameters:\n    - vids (str): Path to the video file.\n    - chessboardLabel (str): Label for the chessboard (used in YOLO processing).\n    - rotation_angle (float, optional): Angle in degrees to rotate frames. If None, uses 90 degrees clockwise.\n\n    Returns:\n    - list: Results from processing frames.\n    \"\"\"\n    # Initialize MediaPipe Hands.\n    mp_hands = mp.solutions.hands\n    hands = mp_hands.Hands(\n        static_image_mode=False,       # Video stream, so set to False.\n        max_num_hands=2,               # Maximum number of hands to detect.\n        min_detection_confidence=0.7,  # Minimum confidence for detection.\n        min_tracking_confidence=0.7    # Minimum confidence for tracking.\n    )\n    \n    cap = cv2.VideoCapture(vids)\n    \n    if not cap.isOpened():\n        print(f\"Error: Cannot open video file {vids}\")\n        return []\n    \n    # Determine if rotation is needed based on the video file name\n    filename = os.path.basename(vids)\n    should_rotate = \"rotate\" in filename\n    \n    # Retrieve frames per second (FPS) of the video\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    if fps == 0:\n        print(\"Error: Cannot retrieve FPS from the video.\")\n        cap.release()\n        return []\n    \n    # Calculate the frame interval for approximately every 3 seconds\n    interval = int(fps * 9)  # For every ~3 seconds\n    if interval <= 0:\n        print(\"Error: Invalid frame interval calculated.\")\n        cap.release()\n        return []\n    \n    # Calculate the starting frame at 1 second\n    start_frame = int(fps * 1)  # 1 second into the video\n    if start_frame < 0:\n        print(\"Error: Invalid start frame calculated.\")\n        cap.release()\n        return []\n    \n    print(f\"Video FPS: {fps}\")\n    print(f\"Starting processing at frame {start_frame} (1 second).\")\n    print(f\"Processing every {interval} frames (approximately every 3 seconds).\")\n    \n    results = []\n    frame_count = 0\n    \n    while True:\n        ret, frame = cap.read()\n        \n        if not ret:\n            # End of video\n            break\n\n        if frame_count >= start_frame and (frame_count - start_frame) % interval == 0:\n            # Check for hand presence\n            hands_detected = detectHand(frame, hands)\n            if hands_detected:\n                print(f\"Skipped frame {frame_count} (Hands detected).\")\n            else:\n                # Process the captured frame\n                frame_result = testYOLO(frame, chessboardLabel,should_rotate)\n                results.append(frame_result)\n                current_time = frame_count / fps\n                print(f\"Processed frame {frame_count} (Time: {current_time:.2f}s): {frame_result}\")\n        \n        frame_count += 1\n    \n    # Release the video capture and MediaPipe resources\n    cap.release()\n    hands.close()\n    print(\"All results:\", results)\n    \n    return results\n\n# Example usage:\n# results = locateChess('path_to_video.mp4', 'chessboard')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.739357Z","iopub.execute_input":"2024-12-11T04:09:11.739814Z","iopub.status.idle":"2024-12-11T04:09:11.754736Z","shell.execute_reply.started":"2024-12-11T04:09:11.739774Z","shell.execute_reply":"2024-12-11T04:09:11.753672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndef select_points_swapped(\n    merged_points,\n    starting_coord,\n    total_points=81,\n    points_per_column=9,\n    x_threshold=40,\n    y_spacing=10,\n    delta_y=50\n):\n    \"\"\"\n    Selects points grouped into columns based on x-coordinates.\n\n    Parameters:\n    - merged_points: List of tuples or arrays representing points (x, y).\n    - starting_coord: Tuple or array representing the starting coordinate (x, y).\n    - total_points: Total number of points to select.\n    - points_per_column: Maximum number of points to select per column.\n    - x_threshold: Threshold to define the x range for a column.\n    - y_spacing: Minimum spacing between selected points in the y-direction.\n    - delta_y: (Unused in original function; included for consistency)\n\n    Returns:\n    - selected_points: List of selected points as tuples.\n    \"\"\"\n    selected_points = []\n\n    # Convert list to NumPy array for easier processing\n    points_array = np.array(merged_points)\n\n    # Sort points by x-coordinate (ascending)\n    sorted_indices = np.argsort(points_array[:, 1])\n    sorted_points = points_array[sorted_indices]\n\n    # Initialize variables\n    current_start = np.array(starting_coord)\n    points_remaining = total_points\n\n    while points_remaining > 0 and len(sorted_points) > 0:\n        # Compute distances to the current_start point\n        distances = np.linalg.norm(sorted_points - current_start, axis=1)\n        nearest_idx = np.argmin(distances)\n        nearest_point = sorted_points[nearest_idx]\n        print(\"near\", nearest_point)\n\n        # If the nearest point is too far left, remove points to the left\n        if nearest_point[0] < starting_coord[0] - x_threshold:\n            # Remove points with x < starting_coord[0] - x_threshold\n            sorted_points = sorted_points[sorted_points[:, 0] >= starting_coord[0] - x_threshold]\n            if len(sorted_points) == 0:\n                break\n            continue        \n\n        # Define the x range for the current column\n        x_min = nearest_point[0] - x_threshold\n        x_max = nearest_point[0] + x_threshold\n\n        # Select points within this column\n        column_mask = (sorted_points[:, 0] >= x_min) & (sorted_points[:, 0] <= x_max)\n        column_points = sorted_points[column_mask]\n\n        if len(column_points) == 0:\n            break  # No more points to select\n\n        # Extract the y-coordinate of the nearest point\n        y_nearest = nearest_point[1]\n\n        # **New Step:** Filter points to have y >= y_nearest\n        column_points = column_points[column_points[:, 1] >= y_nearest]\n\n        if len(column_points) == 0:\n            # If no points satisfy y >= y_nearest, skip to next column\n            sorted_points = sorted_points[~column_mask]\n            current_start = np.array([x_max + 1, current_start[1]])  # Move to the right of the current column\n            continue\n\n        # Sort column points by y-coordinate (ascending)\n        column_sorted_indices = np.argsort(column_points[:, 1])\n        column_sorted_points = column_points[column_sorted_indices]\n\n        last_selected_y = None\n\n        # Select the first 'points_per_column' points, ensuring y difference > y_spacing\n        selected_column_points = []\n        for pt in column_sorted_points:\n            if last_selected_y is None or abs(pt[1] - last_selected_y) > y_spacing:\n                selected_column_points.append(pt)\n                last_selected_y = pt[1]\n                points_remaining -= 1\n                if points_remaining == 0 or len(selected_column_points) == points_per_column:\n                    break\n\n        # Add the selected column points to the overall selected points\n        for pt in selected_column_points:\n            selected_points.append(tuple(pt))\n\n        # Remove selected points from sorted_points\n        sorted_points = sorted_points[~column_mask]\n\n        # Update current_start for the next column (move to the right of the current column)\n        current_start = np.array([x_max + 1, current_start[1]])\n\n    return selected_points\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.756219Z","iopub.execute_input":"2024-12-11T04:09:11.756624Z","iopub.status.idle":"2024-12-11T04:09:11.77338Z","shell.execute_reply.started":"2024-12-11T04:09:11.75659Z","shell.execute_reply":"2024-12-11T04:09:11.77224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport cv2\nimport numpy as np\nimport os\nimport string\n\ndef create_chessboard_labels(grid_points,rotate=False):\n        # Sort grid points into rows based on y-coordinates\n        # grid_points = sorted(grid_points, key=lambda p: (-p[1], p[0]))  # Sort by y descending, then x ascending\n        if(rotate):\n            grid_mod_9 = [grid_points[i::9] for i in range(9)]\n            grid_points = [item for sublist in grid_mod_9 for item in sublist]\n            print(\"Grid\",grid_points)\n\n        rows = [grid_points[i:i + 9] for i in range(0, len(grid_points), 9)]\n        \n        labels = {}\n        total_rows = len(rows) - 1  # Number of squares vertically\n\n        for row_index in range(total_rows):\n            for col_index in range(8):  # 8 squares horizontally\n                # Columns labeled from 'h' to 'a' (left to right)\n                column_label = chr(104 - col_index)  # 'h' (104) to 'a' (97)\n\n                # Rows labeled from '1' to '8' (top to bottom)\n                row_label = row_index + 1  # '1' is top row, '8' is bottom row\n                label = f\"{column_label}{row_label}\"\n\n                # Define square boundaries using four points\n                square = {\n                    \"top_left\": rows[row_index][col_index],\n                    \"top_right\": rows[row_index][col_index + 1],\n                    \"bottom_left\": rows[row_index + 1][col_index],\n                    \"bottom_right\": rows[row_index + 1][col_index + 1],\n                }\n                labels[label] = square\n\n        # Debug: Print all labels with their boundaries\n        # for label, square in labels.items():\n        #     print(f\"{label}: {square}\")\n        # print(labels)\n        return labels\n\ndef get_chessboard_label(x, y, chessboard_labels):\n        for label, square in chessboard_labels.items():\n        # Extract all x and y coordinates to determine boundaries\n            x_coords = [square[\"top_left\"][0], square[\"top_right\"][0],\n                        square[\"bottom_left\"][0], square[\"bottom_right\"][0]]\n            y_coords = [square[\"top_left\"][1], square[\"top_right\"][1],\n                        square[\"bottom_left\"][1], square[\"bottom_right\"][1]]\n            \n            x_min = min(x_coords)\n            x_max = max(x_coords)\n            y_min = min(y_coords)\n            y_max = max(y_coords)\n            \n            # Debug: Print boundaries and point\n            # print(f\"Checking {label}: x[{x_min}, {x_max}], y[{y_min}, {y_max}] with point ({x}, {y})\")\n            \n            if (x_min <= x <= x_max) and (y_min <= y <= y_max):\n                return label\n        return None\n\n\n\ndef select_points(merged_points, starting_coord, total_points=81, points_per_row=9, y_threshold=10,x_spacing=10, delta_x=50):\n    selected_points = []\n\n    # Convert list to NumPy array for easier processing\n    points_array = np.array(merged_points)\n\n    # Sort points by y-coordinate (ascending)\n    sorted_indices = np.argsort(points_array[:, 1])\n    sorted_points = points_array[sorted_indices]\n\n    # Initialize variables\n    current_start = np.array(starting_coord)\n    points_remaining = total_points\n\n    while points_remaining > 0 and len(sorted_points) > 0:\n        # Compute distances to the current_start point\n        distances = np.linalg.norm(sorted_points - current_start, axis=1)\n        nearest_idx = np.argmin(distances)\n        nearest_point = sorted_points[nearest_idx]\n        print(\"near\",nearest_point)\n\n        if nearest_point[1] < starting_coord[1]-y_threshold:\n            # Remove points with y < starting_coord[1]\n            sorted_points = sorted_points[sorted_points[:, 1] >= starting_coord[1]-y_threshold]\n            if len(sorted_points) == 0:\n                break\n            continue        \n\n\n        # Define the y range for the current row\n        y_min = nearest_point[1] -  y_threshold\n        y_max = nearest_point[1] +  y_threshold\n\n        # Select points within this row\n        row_mask = (sorted_points[:, 1] >= y_min) & (sorted_points[:, 1] <= y_max)\n        row_points = sorted_points[row_mask]\n\n        if len(row_points) == 0:\n            break  # No more points to select\n\n        # Extract the x-coordinate of the nearest point\n        x_nearest = nearest_point[0]\n\n        # **New Step:** Filter points to have x >= x_nearest\n        row_points = row_points[row_points[:, 0] >= x_nearest]\n\n        if len(row_points) == 0:\n            # If no points satisfy x >= x_nearest, skip to next row\n            sorted_points = sorted_points[~row_mask]\n            current_start = np.array([current_start[0], y_max + 1])  # Move below the current row\n            continue\n\n        # Sort row points by x-coordinate (ascending)\n        row_sorted_indices = np.argsort(row_points[:, 0])\n        row_sorted_points = row_points[row_sorted_indices]\n\n        last_selected_x = None\n\n        # Select the first 'points_per_row' points, ensuring x difference > 20\n        selected_row_points = []\n        for pt in row_sorted_points:\n            if last_selected_x is None or abs(pt[0] - last_selected_x) > 10:\n                selected_row_points.append(pt)\n                last_selected_x = pt[0]\n                points_remaining -= 1\n                if points_remaining == 0 or len(selected_row_points) == points_per_row:\n                    break\n\n        # Add the selected row points to the overall selected points\n        for pt in selected_row_points:\n            selected_points.append(tuple(pt))\n\n        # Remove selected points from sorted_points\n        sorted_points = sorted_points[~row_mask]\n\n        # Update current_start for the next row (move below the current row)\n        current_start = np.array([current_start[0], y_max + 1])\n\n    return selected_points\n\n\n# Line detection function\ndef detect_lines(image, starting_coord=(147, 538), border=[],rotated=False):\n    # Convert to grayscale and apply Gaussian blur\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n    edges = cv2.Canny(blurred, 50, 150)\n\n    # Adjusted Hough Line Transform parameters\n    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi / 180, threshold=100, minLineLength=30, maxLineGap=120)\n\n    def extend_line(x1, y1, x2, y2, img_width, img_height):\n        if x1 == x2:  # Vertical line\n            return x1, 0, x2, img_height\n        slope = (y2 - y1) / (x2 - x1)\n        intercept = y1 - slope * x1\n\n        # Calculate intersection points with image borders\n        y_at_x0 = intercept\n        y_at_xmax = slope * img_width + intercept\n        x_at_y0 = -intercept / slope\n        x_at_ymax = (img_height - intercept) / slope\n\n        # Determine the two points where the line intersects the image edges\n        points = []\n        if 0 <= y_at_x0 <= img_height:\n            points.append((0, int(y_at_x0)))\n        if 0 <= y_at_xmax <= img_height:\n            points.append((img_width, int(y_at_xmax)))\n        if 0 <= x_at_y0 <= img_width:\n            points.append((int(x_at_y0), 0))\n        if 0 <= x_at_ymax <= img_width:\n            points.append((int(x_at_ymax), img_height))\n\n        # Return the first two points as the extended line\n        return points[0][0], points[0][1], points[1][0], points[1][1]\n\n    img_height, img_width = image.shape[:2]\n    extended_lines = []\n    vertical_lines = []\n    horizontal_lines = []\n\n    if lines is not None:\n        for line in lines:\n            x1, y1, x2, y2 = line[0]\n            x1_ext, y1_ext, x2_ext, y2_ext = extend_line(x1, y1, x2, y2, img_width, img_height)\n            extended_lines.append((x1_ext, y1_ext, x2_ext, y2_ext))\n\n            # Check for vertical or horizontal lines\n            slope = (y2 - y1) / (x2 - x1) if x2 != x1 else float('inf')  # Handle vertical lines\n            if abs(slope) > 1:  # Horizontal lines (near zero slope)\n                horizontal_lines.append((x1_ext, y1_ext, x2_ext, y2_ext))\n            else:\n                vertical_lines.append((x1_ext, y1_ext, x2_ext, y2_ext))\n\n            # Draw each extended line on the image\n            cv2.line(image, (x1_ext, y1_ext), (x2_ext, y2_ext), (0, 255, 0), 2)  # Green line for detection\n\n    # Function to find the intersection of two lines\n    def intersection(line1, line2):\n        x1, y1, x2, y2 = map(float, line1)\n        x3, y3, x4, y4 = map(float, line2)\n\n        # Calculate determinant\n        det = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)\n        if abs(det) == 0:  # Parallel lines\n            return None\n\n        # Calculate intersection point\n        px = ((x1 * y2 - y1 * x2) * (x3 - x4) - (x1 - x2) * (x3 * y4 - y3 * x4)) / det\n        py = ((x1 * y2 - y1 * x2) * (y3 - y4) - (y1 - y2) * (x3 * y4 - y3 * x4)) / det\n        return (int(px), int(py))\n\n    # Function to merge close points\n    def merge_close_points(points, threshold=15):\n        merged_points = []\n        for point in points:\n            if not any(np.linalg.norm(np.array(point) - np.array(existing_point)) < threshold for existing_point in merged_points):\n                merged_points.append(point)\n        return merged_points\n\n    # Find intersections only between horizontal and vertical lines\n    intersection_points = []\n    for v_line in vertical_lines:\n        for h_line in horizontal_lines:\n            point = intersection(v_line, h_line)\n            if point:\n                intersection_points.append(point)\n\n    # Merge close points and filter valid points\n    merged_points = merge_close_points(intersection_points, threshold=25)\n    print(merged_points)\n\n    # Draw filtered points on the image\n    # for point in merged_points:\n    #     cv2.circle(image, point, 6, (0, 0, 255), -1)  # Red circle for intersections\n    y_coords = [point[1] for point in border]\n    # Calculate the absolute differences\n    print(\"Y\",y_coords)\n    diff_1 = abs(y_coords[0] - y_coords[1])\n    diff_2 = abs(y_coords[2] - y_coords[3])\n    # Find the maximum difference\n    max_diff = max(diff_1, diff_2)\n    print(max_diff)\n\n    x_coords = [point[0] for point in border]\n    print(\"X Coordinates:\", x_coords)\n\n    # Calculate the absolute differences for x-coordinates\n    diff_x1 = abs(x_coords[0] - x_coords[1])\n    diff_x2 = abs(x_coords[2] - x_coords[3])\n\n    # Find the maximum difference among x-coordinates\n    max_diff_x = max(diff_x1, diff_x2)\n    print(\"Maximum X Difference:\", max_diff_x)\n\n    if(rotated):\n        # merged_points = [(y, x) for (x, y) in merged_points]\n        selected_points = select_points_swapped(merged_points, starting_coord,x_threshold=max_diff_x)\n    else:\n        selected_points = select_points(merged_points, starting_coord, total_points=81, points_per_row=9, y_threshold=max_diff)\n    print(\"checkMergePoint\",merged_points)\n    print('start',starting_coord)\n    print(selected_points)\n    chessboard_labels = create_chessboard_labels(selected_points,rotated)\n\n    # Test the function with an example coordinate\n\n    print(selected_points)\n    for point in selected_points:\n        cv2.circle(image, point, 6, (0, 0, 255), -1)  # Red circle for intersections\n        # Prepare the coordinate text\n        coord_text = f'({point[0]}, {point[1]})'\n        # Choose a font scale and thickness\n        font_scale = 0.5\n        thickness = 1\n        # Get the size of the text to create a background rectangle\n        (text_width, text_height), baseline = cv2.getTextSize(coord_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n        # Position the text with an offset\n        text_x = point[0] + 10\n        text_y = point[1] - 10\n        # Ensure the text doesn't go outside the image boundaries\n        if text_x + text_width > img_width:\n            text_x = point[0] - text_width - 10\n        if text_y - text_height < 0:\n            text_y = point[1] + text_height + 10\n        # Draw a filled rectangle as background for better readability\n        cv2.rectangle(image, (text_x, text_y - text_height - baseline), \n                             (text_x + text_width, text_y + baseline), \n                             (255, 255, 255), cv2.FILLED)\n        # Put the text on top of the rectangle\n        cv2.putText(image, coord_text, (text_x, text_y), \n                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness, cv2.LINE_AA)\n\n    return image,merged_points,chessboard_labels\n\n\n# Video processing function\ndef process_video_with_fixed_board(video_path):\n    cap = cv2.VideoCapture(video_path)\n    filename = os.path.basename(video_path)\n    should_rotate = \"rotate\" in filename\n\n    if not cap.isOpened():\n        print(\"Error: Could not open video.\")\n        return\n\n    first_frame = True\n    processed_first_frame = None\n    img = None\n\n    # Get video properties to determine the display size\n    fps = cap.get(cv2.CAP_PROP_FPS)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    aspect_ratio = width / height\n    window_width = 480  # Set a fixed window size width (can be adjusted)\n    window_height = int(window_width / aspect_ratio)\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            print(\"End of video or unable to read frame.\")\n            break\n        if first_frame:\n            print(\"Processing the first frame...\")\n            img = frame.copy()\n            borderPoints = detect_chessboard_edges(img)\n            sorted_borderPoints = sorted(borderPoints, key=distance_squared)\n            # print(sorted_borderPoints)\n            processed_first_frame,points,chessboardLabel = detect_lines(frame,sorted_borderPoints[0],sorted_borderPoints,rotated=should_rotate)\n            first_frame = False\n        # Resize frame while maintaining aspect ratio\n        resized_frame = cv2.resize(frame, (window_width, window_height))\n        # Resize processed_first_frame to match the resized frame size\n        processed_first_frame_resized = cv2.resize(processed_first_frame, (window_width, window_height))\n        origin = cv2.resize(frame, (window_width, window_height))\n        # Blend the resized frames\n        output_frame = cv2.addWeighted(resized_frame, 0.7, processed_first_frame_resized, 0.3, 0)\n        # cv2.imshow(\"Chessboard Tracking\", frame)\n        # cv2.waitKey(0)\n        captured_frame = output_frame.copy()\n        break\n        # Quit on 'q' key\n        if cv2.waitKey(30) & 0xFF == ord(\"q\"):\n            break     \n    cap.release()\n    # cv2.destroyAllWindows()\n    return captured_frame,img,points,chessboardLabel\n\ndef testYOLO(testImg,chessboard_labels,rotate=False):\n    detected_chesses = []  # Initialize the list to store (chessname, label) tuples\n    if testImg is not None:\n        # Save the processed frame to a temporary file\n        temp_image_path = \"temp_test_image.jpg\"\n        cv2.imwrite(temp_image_path, testImg)\n\n        # Load the YOLO model\n        model = YOLO(\"/kaggle/input/chess_detection_x75/pytorch/default/1/chess_model_x_75.pt\")  # Use forward slashes for cross-platform compatibility\n\n        # Run prediction on the saved image\n        results = model.predict(source=temp_image_path, imgsz=640)\n\n        # Define the class mapping based on your provided class list\n        class_to_chess = {\n            0: \"bishop\",\n            1: \"black-bishop\",\n            2: \"black-king\",\n            3: \"black-knight\",\n            4: \"black-pawn\",\n            5: \"black-queen\",\n            6: \"black-rook\",\n            7: \"white-bishop\",\n            8: \"white-king\",\n            9: \"white-knight\",\n            10: \"white-pawn\",\n            11: \"white-queen\",\n            12: \"white-rook\",\n        }\n\n        # Iterate through the detection results\n        for result in results:\n            for box in result.boxes.data.tolist():  # Each box is [x1, y1, x2, y2, confidence, class]\n                x1, y1, x2, y2, confidence, cls = box\n                x_center = int((x1 + x2) / 2)\n                y_center = int(abs(y2-y1)*3/4+y1)\n\n                # Map the class index to a chess piece name\n                chess_class = int(cls)\n                chess_name = class_to_chess.get(chess_class, \"Unknown\")\n                confidence_score = confidence\n\n                # Map the (x, y) coordinates to a chessboard label\n                print(chessboard_labels)\n                label = get_chessboard_label(x_center, y_center, chessboard_labels)\n\n\n                # Append the tuple to the list\n                detected_chesses.append((chess_name, label, confidence_score))\n\n                # Optional: Print debug information\n                print(f\"Detected {chess_name} at {label} with confidence {confidence_score:.2f}\")\n\n        # Display the prediction result with bounding boxes\n        for result in results:\n            annotated_frame = result.plot()  # Annotated image with bounding boxes\n            scale_width = 1400 / annotated_frame.shape[1]\n            scale_height = 1200 / annotated_frame.shape[0]\n            scale = min(scale_width, scale_height)\n            resized_frame = cv2.resize(annotated_frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n            # cv2.imshow(\"<picture_name\", resized_frame)\n            # cv2.waitKey(0)\n            # cv2.destroyAllWindows()\n            # cv2.imshow(\"YOLO Detection Result\", annotated_frame)\n\n        # Wait for user to close the window\n        # cv2.waitKey(0)\n        # cv2.destroyAllWindows()\n\n    else:\n        print(\"No image was processed.\")\n    \n    print(detected_chesses)\n\n    return detected_chesses\n\n# Main Script\n# video_path = r\"D:\\CP31\\DigImProj\\chess_dataset\\vids\\2_Move_rotate_student.mp4\"# Replace with your video path\n# video_path = r\"chess_dataset/vids/2_Move_rotate_student_rotated.mp4\"# Replace with your video path\n# video_path = r\"D:\\CP31\\DigImProj\\chess_dataset\\vids\\2_Move_rotate_student_rotated.mp4\"  # Replace with your video path\n# video_path = r\"D:\\CP31\\DigImProj\\chess_dataset\\vids\\6_Move_student.mp4\"  # Replace with your video path\n# video_path = r\"D:\\CP31\\DigImProj\\chess_dataset\\vids\\8_Move_student.mp4\"  # Replace with your video path\n# new_video_path=rotate_video_swap_dimensions(video_path)\n\n# Proceed with processing the video\n# testImg, origins, points, chessboardLabel = process_video_with_fixed_board(video_path)\n# print(points)\n# cv2.imshow(\"Captured First Frame\", testImg)\n# cv2.waitKey(0)  \n# testYOLO(origins,chessboardLabel)\n# locateChess(video_path,chessboardLabel)\n# data = locateChess(video_path,chessboardLabel)\n# tryData = handleMultipleInput(handleduplicateLabel(data))\n# output = formatOutput(lastResult(tryData))\n# print(output)\n     \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.775286Z","iopub.execute_input":"2024-12-11T04:09:11.775756Z","iopub.status.idle":"2024-12-11T04:09:11.835171Z","shell.execute_reply.started":"2024-12-11T04:09:11.775708Z","shell.execute_reply":"2024-12-11T04:09:11.834025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Define the directory containing the videos\nvideo_dir = '/kaggle/input/cu-chess-detection/Chess Detection Competition/test_videos'\n\n# Initialize a list to store the results\nresults = []\n\n# Iterate over each file in the video directory\nfor filename in os.listdir(video_dir):\n    # Check if the file is a video (e.g., ends with .mp4)\n    if filename.endswith('.mp4'):\n        video_path = os.path.join(video_dir, filename)\n        filename = os.path.basename(video_path)\n        rotate = \"rotate\" in filename\n        if(rotate):\n            video_path=rotate_video_swap_dimensions(video_path)\n        # else:\n        #     print('skip')\n        #     continue\n    #-------------------------------------------\n        try:\n            # Process the video\n            result = process_video_with_fixed_board(video_path)\n            \n            # Check if the function returned valid output\n            if result is None:\n                raise ValueError(f\"process_video_with_fixed_board returned None for video {video_path}\")\n            \n            rigtestImg, oins, points, chessboardLabel = result\n            \n            data = locateChess(video_path, chessboardLabel)\n        \n            cleanData = handleduplicateLabel(data)\n            tryData = handleMultipleInput(cleanData)\n            lenData = getAmountChessPiece(tryData)\n            output = formatOutput(lastResult(tryData))\n            \n            # Append the result to the list\n            results.append({\n                'row_id': filename,      # Using the video filename as the ID\n                'output': output         # The result from lastResult\n            })\n        \n        except Exception as e:\n            # Handle any exceptions and optionally log them\n            print(f\"Error processing {filename}: {e}\")\n            results.append({\n                'row_id': filename,\n                'output': f\"Error: {e}\"\n            })\n\n        # print(\"len: \", len(results))\n\n##BONUS\n#===============================================================================================================\nbonus_dir=\"/kaggle/input/cu-chess-detection/Chess Detection Competition/bonus_video/Bonus Long Video Label.mp4\"\nif result is None:\n    raise ValueError(f\"process_video_with_fixed_board returned None for video {bonus_dir}\")\nrigtestImg, oins, points, chessboardLabel = result\ndata = locateChess(bonus_dir, chessboardLabel)\ncleanData = handleduplicateLabel(data)\ntryData = handleMultipleInput(cleanData)\nlenData = getAmountChessPiece(tryData)\noutput = formatOutput(lastResult(tryData))\nresults.append({\n    'row_id': '(Bonus)Long_video_student.mp4',\n    'output': output\n})\n#===============================================================================================================\n\n# Create a DataFrame from the results\ndf = pd.DataFrame(results)\ndf = df.dropna(how='all')\n# Add the custom row\nprint(df)\n\n# Specify the path where you want to save the CSV\ncsv_output_path = '/kaggle/working/submission.csv'\n\n# Save the DataFrame to a CSV file\ndf.to_csv(csv_output_path, index=False, mode='w')\n\n# Remove trailing newline by reading the file and rewriting without the final newline\nwith open(csv_output_path, 'r') as file:\n    lines = file.readlines()\n\n# Rewrite the file, excluding the trailing newline in the last line\nwith open(csv_output_path, 'w') as file:\n    file.writelines(lines[:-1] + [lines[-1].rstrip('\\n')])\n\nprint(f\"Results have been saved to {csv_output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:09:11.836743Z","iopub.execute_input":"2024-12-11T04:09:11.837233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}